{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Quality Metrics Result Analysis**\n",
    "\n",
    "In this notebook, the raw energy consumption data, with different configurations of inference batch sizes, is analyzed. The results are averaged over the five runs, along with the computation of the standard deviation for each tracked parameter."
   ],
   "id": "2abf49263085dc4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T18:41:33.986587Z",
     "start_time": "2025-04-30T18:41:33.974479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ],
   "id": "678ebae5d6fe584d",
   "outputs": [],
   "execution_count": 179
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# get working directory, necessary to gather the data to be analyzed\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current Working Directory: {current_dir}\")\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "print(f\"Parent Directory: {parent_dir}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Helper Functions**\n",
    "Useful functions to properly format labels and to obtain final results from raw inference energy consumption data."
   ],
   "id": "e8ae7150f3cdaee7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T18:41:34.054166Z",
     "start_time": "2025-04-30T18:41:34.044986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_model_emissions(model_nomen, audiocaps_csv, clotho_csv, output_csv):\n",
    "    \"\"\"\n",
    "    Aggregates GPU energy and emission data for a specific model from AudioCaps\n",
    "    and Clotho datasets based on training steps.\n",
    "\n",
    "    This function reads emission data from two CSV files (one for AudioCaps and\n",
    "    one for Clotho), extracts the number of training steps from the 'project_name'\n",
    "    column, groups the data by steps and baseline ('audiocaps' or 'clotho'),\n",
    "    sums the 'gpu_energy' and 'emissions' for each group, and combines the results\n",
    "    into a single DataFrame. The combined data is then saved to a new CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_nomen : str\n",
    "        The name of the model being analyzed. This name will be added as a\n",
    "        column in the output DataFrame.\n",
    "\n",
    "    audiocaps_csv : str\n",
    "        The file path to the CSV file containing emission data for the\n",
    "        AudioCaps dataset. This file is expected to have columns including\n",
    "        'project_name', 'gpu_energy', and 'emissions'.\n",
    "\n",
    "    clotho_csv : str\n",
    "        The file path to the CSV file containing emission data for the\n",
    "        Clotho dataset. This file is expected to have columns including\n",
    "        'project_name', 'gpu_energy', and 'emissions'.\n",
    "\n",
    "    output_csv : str\n",
    "        The file path where the aggregated results will be saved as a CSV file.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A pandas DataFrame containing the aggregated data with columns:\n",
    "        'model', 'steps', 'baseline', 'gpu_energy', and 'emissions'.\n",
    "        The function also saves this DataFrame to the path specified by\n",
    "        `output_csv`.\n",
    "    \"\"\"\n",
    "    def extract_steps(project_name):\n",
    "        match = re.search(r'(\\d+)-steps', project_name)\n",
    "        return int(match.group(1)) if match else None\n",
    "\n",
    "    df_audiocaps = pd.read_csv(audiocaps_csv)\n",
    "    df_clotho = pd.read_csv(clotho_csv)\n",
    "\n",
    "    df_audiocaps['steps'] = df_audiocaps['project_name'].apply(extract_steps)\n",
    "    df_audiocaps['baseline'] = 'audiocaps'\n",
    "    df_clotho['steps'] = df_clotho['project_name'].apply(extract_steps)\n",
    "    df_clotho['baseline'] = 'clotho'\n",
    "\n",
    "    agg_audiocaps = df_audiocaps.groupby(['steps', 'baseline']).agg({\n",
    "        'gpu_energy': 'sum',\n",
    "        'emissions': 'sum'\n",
    "    }).reset_index()\n",
    "    agg_clotho = df_clotho.groupby(['steps', 'baseline']).agg({\n",
    "        'gpu_energy': 'sum',\n",
    "        'emissions': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    agg_data = pd.concat([agg_audiocaps, agg_clotho], ignore_index=True)\n",
    "    agg_data['model'] = model_nomen\n",
    "    agg_data = agg_data[['model', 'steps', 'baseline', 'gpu_energy', 'emissions']]\n",
    "\n",
    "    agg_data.to_csv(output_csv, index=False)\n",
    "    print(f\"Aggregated CSV for model '{model_nomen}' saved to '{output_csv}'.\")\n",
    "    return agg_data"
   ],
   "id": "cbc04cdfbd8abc2",
   "outputs": [],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T18:41:34.093771Z",
     "start_time": "2025-04-30T18:41:34.084192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def getdata(modello):\n",
    "    \"\"\"\n",
    "    Retrieves and merges quality metrics (FAD, CLAP) and emission data for a specific model.\n",
    "\n",
    "    This function reads FAD and CLAP scores from CSV files located in a\n",
    "    structured directory based on the model name. It then reads corresponding\n",
    "    emission data (emissions, gpu_energy) and merges it with the quality\n",
    "    metrics based on 'steps' and 'baseline'. The merged data, excluding\n",
    "    the first column, is printed to the console.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    modello : str\n",
    "        The name of the model for which to retrieve and merge data. This is used\n",
    "        to construct the file paths for quality metrics and emission data.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        The function does not return a value but prints the merged DataFrame\n",
    "        (excluding the first column and without the index) to the standard output.\n",
    "\n",
    "    Assumed Dependencies:\n",
    "    ---------------------\n",
    "    - `current_dir`: A global or externally defined variable specifying the\n",
    "      base directory where the 'results' folder is located.\n",
    "    - `metrics`: A global or externally defined dictionary mapping metric names\n",
    "      (\"FAD\", \"CLAP\") to a list containing the corresponding column name\n",
    "      in the quality metrics CSV files (e.g., {\"FAD\": [\"fad_score\"], \"CLAP\": [\"clap_score\"]}).\n",
    "\n",
    "    Input Files:\n",
    "    ------------\n",
    "    - `{current_dir}\\results\\quality_metrics\\FAD\\{modello}_fad_scores.csv`:\n",
    "      Expected to contain columns 'steps', 'baseline', and the FAD score column\n",
    "      named according to `metrics[\"FAD\"][0]`.\n",
    "    - `{current_dir}\\results\\quality_metrics\\CLAP\\{modello}_clap_scores.csv`:\n",
    "      Expected to contain columns 'steps', 'baseline', and the CLAP score column\n",
    "      named according to `metrics[\"CLAP\"][0]`.\n",
    "    - `{current_dir}\\results\\quality_metrics\\emissions\\{modello}\\{modello}_emissions.csv`:\n",
    "      Expected to contain columns 'steps', 'baseline', 'emissions', and 'gpu_energy'.\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    - The function prints a string representation of the merged pandas DataFrame\n",
    "      (excluding the first column and the index) to the console.\n",
    "    \"\"\"\n",
    "    merged_data = pd.DataFrame()\n",
    "\n",
    "    for metr in [\"FAD\", \"CLAP\"]:\n",
    "        file_path = rf\"{current_dir}\\results\\quality_metrics\\{metr}\\{modello}_{metrics[metr][0]}s.csv\"\n",
    "        data = pd.read_csv(file_path)\n",
    "        en_path = rf\"{current_dir}\\results\\quality_metrics\\emissions\\{modello}\\{modello}_emissions.csv\"\n",
    "        energy = pd.read_csv(en_path)\n",
    "        for col in ['emissions', 'gpu_energy']:\n",
    "            data = data.merge(energy[['steps', 'baseline', col]], on=['steps', 'baseline'], how='left')\n",
    "\n",
    "        if merged_data.empty: merged_data = data\n",
    "        else: merged_data.insert(loc=4, column=\"clap_score\", value=data[\"clap_score\"])\n",
    "\n",
    "    print(merged_data.iloc[:, 1:].to_string(index=False))"
   ],
   "id": "a29ed65446ba24fc",
   "outputs": [],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T18:41:34.120939Z",
     "start_time": "2025-04-30T18:41:34.113141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_metrics(modello):\n",
    "    print(\"-\" * 70)\n",
    "    print(modello.center(70))\n",
    "    print(\"-\" * 70)\n",
    "    getdata(modello)\n",
    "    print(\"\\n\")"
   ],
   "id": "e686af90ff1ed917",
   "outputs": [],
   "execution_count": 183
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Data analysis**\n",
    "Using the previously defined functions, we now can analyze the data obtained for the five different runs for all considered models."
   ],
   "id": "25bb38a688a950d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics = {\"FAD\": [\"fad_score\", \"FAD\"],\n",
    "           \"CLAP\": [\"clap_score\", \"Contrastive Language-Audio Pretraining Score\"]}\n",
    "models = [\"AudioLDM\", \"AudioLDM2\", \"SAO\", \"MAA\", \"MAA2\", \"Tango\", \"Tango2\"]\n",
    "\n",
    "for model in models:\n",
    "    audiocaps_file = fr\"{current_dir}\\results\\quality_metrics\\emissions\\{model}\\{model}_audiocaps.csv\"\n",
    "    clotho_file = fr\"{current_dir}\\results\\quality_metrics\\emissions\\{model}\\{model}_clotho.csv\"\n",
    "    output_file = fr\"{current_dir}\\results\\quality_metrics\\emissions\\{model}\\{model}_emissions.csv\"\n",
    "    get_model_emissions(model, audiocaps_file, clotho_file, output_file)"
   ],
   "id": "f44b2ad70f35e155",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T18:41:34.675221Z",
     "start_time": "2025-04-30T18:41:34.645050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# analyze single models\n",
    "model_name = \"AudioLDM\" # model = \"AudioLDM2\" # model = \"MAA\" # . . .\n",
    "\n",
    "print_metrics(model_name)"
   ],
   "id": "bfba46d50db60920",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "                               AudioLDM                               \n",
      "----------------------------------------------------------------------\n",
      " steps  baseline  fad_score  clap_score  emissions  gpu_energy\n",
      "    10    clotho   0.623181    0.328345   0.003523    0.005168\n",
      "    25    clotho   0.566925    0.379216   0.006288    0.009578\n",
      "    50    clotho   0.568657    0.385669   0.010888    0.016902\n",
      "   100    clotho   0.574913    0.390508   0.020251    0.031703\n",
      "   150    clotho   0.564129    0.407495   0.029547    0.046457\n",
      "   200    clotho   0.574102    0.383884   0.038766    0.061184\n",
      "    10 audiocaps   0.332963    0.308149   0.003489    0.005166\n",
      "    25 audiocaps   0.229715    0.326384   0.006208    0.009555\n",
      "    50 audiocaps   0.222753    0.322408   0.010784    0.016890\n",
      "   100 audiocaps   0.210654    0.316021   0.019936    0.031586\n",
      "   150 audiocaps   0.204954    0.340574   0.029099    0.046297\n",
      "   200 audiocaps   0.207078    0.311856   0.038232    0.061027\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T18:41:34.814194Z",
     "start_time": "2025-04-30T18:41:34.697265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model in models:\n",
    "    print_metrics(model)"
   ],
   "id": "5972f1fdeb155a30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "                               AudioLDM                               \n",
      "----------------------------------------------------------------------\n",
      " steps  baseline  fad_score  clap_score  emissions  gpu_energy\n",
      "    10    clotho   0.623181    0.328345   0.003523    0.005168\n",
      "    25    clotho   0.566925    0.379216   0.006288    0.009578\n",
      "    50    clotho   0.568657    0.385669   0.010888    0.016902\n",
      "   100    clotho   0.574913    0.390508   0.020251    0.031703\n",
      "   150    clotho   0.564129    0.407495   0.029547    0.046457\n",
      "   200    clotho   0.574102    0.383884   0.038766    0.061184\n",
      "    10 audiocaps   0.332963    0.308149   0.003489    0.005166\n",
      "    25 audiocaps   0.229715    0.326384   0.006208    0.009555\n",
      "    50 audiocaps   0.222753    0.322408   0.010784    0.016890\n",
      "   100 audiocaps   0.210654    0.316021   0.019936    0.031586\n",
      "   150 audiocaps   0.204954    0.340574   0.029099    0.046297\n",
      "   200 audiocaps   0.207078    0.311856   0.038232    0.061027\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "                              AudioLDM2                               \n",
      "----------------------------------------------------------------------\n",
      " steps  baseline  fad_score  clap_score  emissions  gpu_energy\n",
      "    10    clotho   0.605248    0.346459   0.006814    0.009349\n",
      "    25    clotho   0.550054    0.382760   0.013090    0.018396\n",
      "    50    clotho   0.540046    0.381822   0.023593    0.033485\n",
      "   100    clotho   0.547215    0.386497   0.044801    0.063973\n",
      "   150    clotho   0.557893    0.377701   0.065646    0.094053\n",
      "   200    clotho   0.567749    0.384738   0.086667    0.124399\n",
      "    10 audiocaps   0.219773    0.318527   0.006785    0.009371\n",
      "    25 audiocaps   0.175657    0.337297   0.013047    0.018358\n",
      "    50 audiocaps   0.181413    0.343946   0.023629    0.033546\n",
      "   100 audiocaps   0.180942    0.339560   0.044537    0.063663\n",
      "   150 audiocaps   0.166648    0.319909   0.065703    0.094167\n",
      "   200 audiocaps   0.180826    0.339337   0.086799    0.124575\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "                                 SAO                                  \n",
      "----------------------------------------------------------------------\n",
      " steps  baseline  fad_score  clap_score  emissions  gpu_energy\n",
      "    10    clotho   0.539391    0.215130   0.010953    0.021983\n",
      "    25    clotho   0.484437    0.296704   0.025280    0.051654\n",
      "    50    clotho   0.486157    0.303551   0.049177    0.101174\n",
      "   100    clotho   0.486733    0.303321   0.096843    0.200186\n",
      "   150    clotho   0.484845    0.304294   0.144857    0.299738\n",
      "   200    clotho   0.485261    0.303519   0.192898    0.399444\n",
      "    10 audiocaps   0.407651    0.281615   0.010962    0.021986\n",
      "    25 audiocaps   0.300320    0.349423   0.025346    0.051813\n",
      "    50 audiocaps   0.298017    0.352756   0.049179    0.101286\n",
      "   100 audiocaps   0.296931    0.354556   0.097049    0.200688\n",
      "   150 audiocaps   0.297937    0.356553   0.144942    0.300123\n",
      "   200 audiocaps   0.297910    0.355685   0.192999    0.400006\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "                                 MAA                                  \n",
      "----------------------------------------------------------------------\n",
      " steps  baseline  fad_score  clap_score  emissions  gpu_energy\n",
      "    10    clotho   0.688554    0.370576   0.005735    0.010524\n",
      "    25    clotho   0.626385    0.426280   0.009451    0.017825\n",
      "    50    clotho   0.596564    0.434529   0.015665    0.029923\n",
      "   100    clotho   0.582987    0.445262   0.028100    0.054026\n",
      "   150    clotho   0.572406    0.448334   0.044782    0.086386\n",
      "   200    clotho   0.571885    0.448404   0.052968    0.102442\n",
      "    10 audiocaps   0.236855    0.244735   0.005733    0.010526\n",
      "    25 audiocaps   0.151590    0.286048   0.009482    0.017774\n",
      "    50 audiocaps   0.131738    0.302820   0.015683    0.029789\n",
      "   100 audiocaps   0.126048    0.304701   0.028029    0.053830\n",
      "   150 audiocaps   0.124532    0.307965   0.044748    0.086134\n",
      "   200 audiocaps   0.120253    0.308357   0.052968    0.102163\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "                                 MAA2                                 \n",
      "----------------------------------------------------------------------\n",
      " steps  baseline  fad_score  clap_score  emissions  gpu_energy\n",
      "    10    clotho   0.598223    0.425406   0.006097    0.011409\n",
      "    25    clotho   0.578642    0.432061   0.009956    0.019304\n",
      "    50    clotho   0.571633    0.426264   0.016468    0.032571\n",
      "   100    clotho   0.565389    0.423957   0.029445    0.059064\n",
      "   150    clotho   0.563515    0.423672   0.046798    0.094719\n",
      "   200    clotho   0.565809    0.426533   0.055445    0.112514\n",
      "    10 audiocaps   0.186171    0.316058   0.006104    0.011412\n",
      "    25 audiocaps   0.180911    0.319647   0.010005    0.019303\n",
      "    50 audiocaps   0.184765    0.317627   0.016468    0.032509\n",
      "   100 audiocaps   0.179042    0.322800   0.029501    0.059053\n",
      "   150 audiocaps   0.181188    0.321100   0.046924    0.094731\n",
      "   200 audiocaps   0.182620    0.324867   0.055611    0.112461\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "                                Tango                                 \n",
      "----------------------------------------------------------------------\n",
      " steps  baseline  fad_score  clap_score  emissions  gpu_energy\n",
      "    10    clotho   0.712348    0.353197   0.016192    0.032362\n",
      "    25    clotho   0.571140    0.421454   0.037255    0.075703\n",
      "    50    clotho   0.558740    0.439680   0.072310    0.147961\n",
      "   100    clotho   0.548408    0.417842   0.142773    0.293032\n",
      "   150    clotho   0.598551    0.414555   0.212963    0.438752\n",
      "   200    clotho   0.558771    0.439551   0.284169    0.585528\n",
      "    10 audiocaps   0.299448    0.294041   0.016107    0.032338\n",
      "    25 audiocaps   0.158284    0.333764   0.037049    0.075672\n",
      "    50 audiocaps   0.145355    0.342672   0.071955    0.147906\n",
      "   100 audiocaps   0.151122    0.345195   0.141640    0.292847\n",
      "   150 audiocaps   0.169492    0.313024   0.212123    0.438890\n",
      "   200 audiocaps   0.151246    0.333510   0.283346    0.585838\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "                                Tango2                                \n",
      "----------------------------------------------------------------------\n",
      " steps  baseline  fad_score  clap_score  emissions  gpu_energy\n",
      "    10    clotho   0.619342    0.500329   0.016239    0.032658\n",
      "    25    clotho   0.554874    0.536049   0.037463    0.076413\n",
      "    50    clotho   0.562725    0.541294   0.072944    0.149429\n",
      "   100    clotho   0.548023    0.537890   0.143913    0.295947\n",
      "   150    clotho   0.577880    0.535014   0.215090    0.443789\n",
      "   200    clotho   0.568753    0.532011   0.286997    0.592072\n",
      "    10 audiocaps   0.189226    0.368893   0.016165    0.032645\n",
      "    25 audiocaps   0.111934    0.387976   0.037311    0.076465\n",
      "    50 audiocaps   0.108758    0.388748   0.072627    0.149598\n",
      "   100 audiocaps   0.107766    0.382449   0.143277    0.296182\n",
      "   150 audiocaps   0.119822    0.366579   0.214390    0.443726\n",
      "   200 audiocaps   0.111850    0.383543   0.285478    0.592264\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 186
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
